# -*- coding: utf-8 -*-
"""MAIS202_FinalProject

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VSF5ZL5dUcADf0a2yZIRGwnkxEtacqEB
"""

# we will start by installing then importing the relevant Python libraries
import csv
import random
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn import linear_model
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# read in the data as pandas dataframes

#parse it

#linear regression

#gradient descent

#regularization

#output

!wget https://raw.githubusercontent.com/MaxB0u/Mais202_car_price_predictor/master/BUICK_preliminary%20result.csv

dataset_filename = 'BUICK_preliminary result.csv'

with open(dataset_filename) as csv_file:
  csv_reader = csv.reader(csv_file) 
  data = list(csv_reader)

#want columns 1,2,3,7,8
print(data)

random.shuffle(data)
X = list() #year,mileage,make,model
y = list() #price


for x in data:
  X.append([int(x[2]),int(x[3]),x[7],x[8]])
  y.append(int(x[1]))
print(X)

#vectorize data so every model and make gets mapped to a number
make = dict()
model = dict()
counter1 = 0
counter2 = 0

for listing in X:
  if listing[2] not in make:
    make[listing[2]] = counter1
    counter1+=1
  
  if listing[3] not in model:
    model[listing[3]] = counter2
    counter2+=1
 

  listing[2] = make[listing[2]] #assign numerical value to make
  listing[3] = model[listing[3]] #assign numerical value to model
print(make)
print(model)
print(X)

def train_test_split(X, y, train_size):
  ### Answer starts here ###
  X_train = []
  X_test = []
  y_train = []
  y_test = []
  split_value = len(X)*train_size

  for i in range(0,len(X)):
    
    if i<split_value:
      X_train.append(X[i])
      y_train.append(y[i])
    else:
      X_test.append(X[i])
      y_test.append(y[i])
  
  return X_train, X_test, y_train, y_test
  ### Answer ends here ###

X_train, X_test, y_train, y_test = train_test_split(X, y, 0.8) #split between training and tst data

#support vector regression
svr_reg = SVR()
svr_reg.fit(X_train,y_train)
y_pred_train = svr_reg.predict(X_train)
print(mean_squared_error(svr_reg.predict(X_train),y_train))
print(mean_squared_error(svr_reg.predict(X_test),y_test))
print(svr_clf.score(X_train, y_train))
print(svr_clf.score(X_test, y_test))

#random forest regression using sickit learning
for_reg = RandomForestRegressor()
for_reg.fit(X_train,y_train)
#print(for_reg.predict(X_train))
print(for_reg.score(X_train, y_train))
print(for_reg.score(X_test, y_test))
print(mean_squared_error(for_reg.predict(X_train),y_train))
print(mean_squared_error(for_reg.predict(X_test),y_test))